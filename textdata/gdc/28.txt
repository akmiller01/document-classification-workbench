G l o b a l
D i g i t a l
C o m p a c t
G o o g l e
3 1
M a r c h
2 0 2 3
Secretary-General
Guterres
and
participants
of
the
Summit
of
the
Future,
Thank
you
for
the
opportunity
to
submit
input
to
the
UN
Global
Digital
Compact.
Our
core
mission
at
Google
is
to
organize
the
world’s
information
and
make
it
universally
accessible
and
useful.
We
believe
that
many
of
the
challenges
of
our
era
can
only
be
effectively
addressed
by
global
collaboration
across
borders.
Whether
it’s
a
pandemic,
climate
change,
or
the
health
of
the
global
economy,
we
live
in
an
interconnected
world
in
which
international
organizations
like
the
United
Nations,
governments,
civil
society,
and
private
sector
businesses
like
Google
must
work
together
to
tackle
humanity’s
collective
challenges
to
realize
a
more
prosperous
future
for
all.
Among
the
most
important
of
those
challenges
is
accelerating
the
world’s
digital
transformation
in
ways
that
advance
opportunity
for
all
people
and
protect
our
planet.
Technological
innovation
holds
tremendous
promise
not
just
to
democratize
access
to
next-generation
tools
but
also
to
accelerate
progress
on
the
UN
Sustainable
Development
Goals.
We
believe
technology
is
a
force
for
good.
We
have
recently
seen
how
technology-enabled
solutions
like
smartphone-based
exposure
notifications
can
support
public
health
authorities
in
the
fight
against
COVID-19,
machine-learning
models
help
reduce
and
optimize
energy
consumption,
and
AI,
when
deployed
responsibly,
can
address
a
host
of
challenges.
At
Google,
we
are
proud
to
be
pushing
the
frontiers
of
innovation,
investing
billions
in
R&D
each
year
to
generate
new
technologies
that
help
address
the
world’s
biggest
cross-border
problems.
But
challenges
remain,
and
we
know
that
the
promise
of
technology
is
not
a
given.
Despite
the
recent
acceleration
of
digital
transformation,
there
are
still
numerous
issues
to
address
before
technology’s
potential
can
be
fully
realized
–
issues
that
can
be
addressed
through
a
truly
collaborative,
multistakeholder
effort
under
the
auspices
of
the
UN
Global
Digital
Compact.
—
1 )
P r o t e c t
t h e
o p e n
i n t e r n e t
( S D G
9 )
The
global
internet
was
built
to
be
a
shared
resource
that
everyone
could
access
wherever
they
lived
-
but
over
the
last
few
years
this
ideal
has
been
increasingly
challenged.
Regulatory
barriers
to
the
free
flow
of
information
across
borders
are
threatening
to
fragment
the
internet.
New
and
revitalized
global
governance
frameworks
are
needed
for
an
increasingly
digitized
world,
and
international
organizations
will
be
critical
to
achieving
them.
Digital
fragmentation
impacts
everyone
using
the
internet.
As
conflicting
regulations
proliferate,
people’s
access
to
information,
privacy
protections,
and
freedom
to
transact
and
communicate
increasingly
vary
depending
on
where
they
are
located.
Digital
fragmentation
has
become
a
significant
barrier
to
international
trade,
with
a
particularly
pernicious
effect
on
small
businesses,
which
lack
the
resources
to
navigate
an
array
of
conflicting
rules.
And
it
discriminates
against
emerging
markets,
as
new
products
become
harder
to
launch
and
scale
on
a
fragmented
Internet
to
all
markets.
In
particular,
we’re
seeing
a
number
of
governments
take
actions
to
crack
down
on
the
free
flow
of
information
and
ideas,
increase
government
surveillance,
and
restrict
access
to
cross-border
internet
services
under
the
banner
of
“cyber-sovereignty.”
In
the
most
extreme
cases,
certain
governments
have
leveraged
technology
to
silence
critical
voices
and
conceal
human
rights
abuses.
Google
actively
works
to
maintain
global
access
to
its
services,
contributes
to
core
internet
standards,
and
continues
to
develop
tools
to
expose
and
oppose
internet
shutdowns
and
cyber-attacks,
but
effectively
countering
the
growing
trend
of
digital
censorship
will
take
a
multistakeholder,
intergovernmental
effort.
As
the
UN
Global
Digital
Compact
and
other
international
efforts
like
the
Declaration
for
the
Future
of
the
Internet
take
shape,
Google
believes
that
discussions
should
be
grounded
in
a
few
common
principles:
●
First,
governments
and
international
organizations
should
strive
to
agree
on
common
standards
to
guide
the
development
of
new
rules
for
digital
technologies,
so
that
consumers
have
consistent
protections
across
borders
and
access
to
digital
tools.
●
Second,
governments
and
international
organizations
should
strive
to
increase
interoperability
between
national
digital
rules
(as
we
have
seen
with
the
US-EU
Data
Privacy
Framework
and
the
Global
Cross
Border
Privacy
Rules
).
●
Third,
governments
and
international
organizations
like
the
UN
should
commit
to
intergovernmental
regulatory
dialogue
to
ensure
that
new
rules
strengthen
shared
values
-
the
GDC
is
an
excellent
opportunity
for
such
dialogue.
●
And
fourth,
governments
and
international
organizations
should
abide
by
core
open
trade
principles
like
non-discriminatory
approaches
to
regulation
that
do
not
single
out
foreign
companies.
2 )
R e s p e c t
h u m a n
r i g h t s
( S D G
1 6 )
In
their
first
letter
to
shareholders,
our
founders
highlighted
Google’s
mission
to
“develop
services
that
significantly
improve
the
lives
of
as
many
people
as
possible.”
This
vision
continues
to
guide
Google.
From
Search
to
YouTube,
Gmail
to
Google
Maps—we’ve
worked
to
ensure
that
our
products
increase
access
to
information,
help
people
connect
with
one
another,
and
amplify
opportunities
around
the
world.
In
doing
so,
Google’s
business,
products,
and
technology
have
long
had
implications
for
the
advancement
of
global
human
rights,
and
we
have
had
a
stake
in
the
conversations
around
the
intersections
of
human
rights
and
digital
governance.
Google
is
guided
by
internationally
recognized
human
rights
standards,
and
we
believe
that
the
future
of
the
internet
must
be
founded
on
them
too.
We
are
committed
to
respecting
the
rights
enshrined
in
the
Universal
Declaration
of
Human
Rights
and
its
implementing
treaties,
as
well
as
upholding
the
standards
established
in
the
United
Nations
Guiding
Principles
on
Business
and
Human
Rights
(UNGPs)
and
in
the
Global
Network
Initiative
Principles
(GNI
Principles).
These
frameworks
are
the
foundation
of
our
responsible
approaches
to
critical
issues
ranging
from
content
to
privacy
to
AI
governance.
We
encourage
greater
industry
adoption
of
these
standards
to
ensure
advancements
in
technology
continue
to
benefit
everyone.
3 )
E x p a n d
a c c e s s
a n d
c o n n e c t i v i t y
t o
t h e
g l o b a l
i n t e r n e t
s o
t h a t
a l l
p e o p l e
c a n
b e n e f i t
f r o m
i t
( S D G
9 )
Connectivity
is
the
foundation
of
an
inclusive
digital
economy,
but
2.7
billion
people
worldwide
remain
disconnected
from
the
global
internet.
We
are
focused
on
developing
infrastructure
that
can
help
bring
the
internet
to
more
people—like
the
subsea
cables
we
are
building
between
Western
Europe
and
the
West
Coast
of
Africa,
which
will
increase
bandwidth
speeds
and
expand
connectivity.
Through
the
Android
ecosystem,
we
are
promoting
the
availability
of
affordable
devices
that
enable
more
users
to
access
the
Internet
and
digital
tools,
so
that
online
participation
is
not
limited
to
those
who
can
afford
luxury
devices.
And
through
support
for
a
responsible
advertising
ecosystem
that
keeps
data
safe
and
secure,
we
are
working
to
keep
the
internet
accessible
to
all,
making
it
possible
for
small
businesses
to
reach
new
customers
locally
and
around
the
globe.
Google
believes
that
an
open,
free,
secure,
resilient
and
interoperable
internet
facilitates
free
expression,
increases
opportunities
for
everyone
with
internet
access,
and
drives
investment
and
innovation.
Closing
the
global
digital
divide
is
not
only
critical
for
ensuring
that
all
people
can
benefit
from
the
opportunities
afforded
by
digital
tools,
but
also
because
we
are
missing
out
on
the
knowledge,
expertise,
and
creativity
that
each
person
who
lacks
access
to
the
internet
has
to
offer
to
the
rest
of
the
world.
We
must
bridge
the
digital
divide
with
a
view
towards
equity,
ensuring
connectivity
to
rural
and
urban
areas
for
all
people,
including
those
with
disabilities.
We
fully
support
legislative,
regulatory,
and
policy
efforts
that
expand
connectivity
and
will
continue
to
play
our
part.
4 )
W e
m u s t
e n s u r e
t h a t
t h e
w o r l d ’ s
d i g i t a l
t r a n s f o r m a t i o n
e n a b l e s
e c o n o m i c
o p p o r t u n i t i e s
f o r
p e o p l e
a c r o s s
t h e
w o r l d
( S D G s
1 ,
3 ,
4 ,
8 ,
1 0 )
More
than
ever,
entrepreneurs
and
existing
businesses
around
the
world
are
leveraging
technology
and
the
internet
to
connect,
create,
and
expand,
bringing
new
jobs
and
economic
opportunity
to
their
communities.
The
internet
is
also
opening
new
opportunities
for
workers
to
build
skills
and
expand
their
own
horizons.
But
these
opportunities
for
entrepreneurs
and
workers
are
not
yet
universally
accessible.
The
last
several
years
presented
once-in-a-generation
challenges
that
have
fallen
hardest
on
emerging
economies.
Yet
emerging
markets
also
have
some
of
the
most
vibrant
economies
and
greatest
entrepreneurial
energy
in
the
world.
With
the
right
policy
frameworks,
they
can
become
ideal
launching
pads
for
future
innovation.
We
call
these
emerging
economies
“
Digital
Sprinters,”
a
subject
on
which
we
released
a
comprehensive
report
in
2020
.
By
becoming
more
digital
these
countries
have
the
potential
to
sprint
ahead
toward
economic
development.
Based
on
our
experiences,
we
believe
governments,
international
organizations,
and
the
private
sector
should
focus
on
four
key
areas:
●
P h y s i c a l
c a p i t a l
:
this
is
about
digital
connectivity
and
infrastructure.
It’s
not
just
about
investment
but
also
how
infrastructure
is
managed.
●
H u m a n
c a p i t a l :
countries
need
a
comprehensive
approach
to
worker
training,
economic
security,
entrepreneurship,
and
combating
discrimination.
●
T e c h n o l o g y :
increasing
the
use
of
data,
artificial
intelligence,
and
cloud
computing,
which
empower
the
growth
of
next-generation
technologies
and
unlock
future
growth.
This
means
new
opportunities
alongside
new
questions
about
how
best
to
harness
these
technologies.
●
C o m p e t i t i v e n e s s :
policies
that
promote
competitive
and
open
markets,
interoperable
regulatory
standards,
and
tax
regimes
that
are
predictable
and
based
on
international
standards.
The
economic
potential
from
digital
transformation
is
huge.
By
2030,
digital
transformation
could
generate
as
much
$3.4
trillion
of
economic
value
in
certain
emerging
markets.
On
the
sidelines
of
the
2022
United
Nations
General
Assembly,
we
expanded
the
measurement
of
potential
gains
in
what
we
call
“Digital
Sprinters”
markets
by
launching
the
Portulans
Institute’s
first
global
Future
Readiness
Economic
Index
.
The
report
covers
124
economies
and
helps
countries
in
assessing
how
ready
they
are
for
the
future,
and
how
they
can
accelerate
their
digital
transformation
for
stronger,
sustainable
and
inclusive
growth.
5 )
P r o m o t e
r e s p o n s i b l e
A r t i f i c i a l
I n t e l l i g e n c e
( A I )
a n d
i n n o v a t i o n
( S D G
9 )
We
believe
that
AI,
including
its
core
methods
such
as
machine
learning
(ML),
is
a
foundational
and
transformational
technology.
AI
enables
innovative
new
uses
of
tools,
products,
and
services,
and
it
is
used
by
billions
of
people
every
day,
as
well
as
businesses,
governments,
and
other
organizations.
AI
can
assist,
complement,
empower,
and
inspire
people
in
almost
every
field,
from
everyday
tasks
to
bold
and
imaginative
endeavors.
It
can
unlock
new
scientific
discoveries
and
opportunities,
and
help
tackle
humanity’s
greatest
challenges—today
and
in
the
future.
AI
will
have
a
significant
impact
on
our
global
society
for
many
years
to
come.
That’s
why
we
established
our
industry-leading
AI
Principles
in
2018.
These
are
backed
by
the
operational
processes
and
structures
necessary
to
ensure
they
are
not
just
words
but
concrete
standards
that
actively
impact
our
research,
products
and
business
decisions
to
ensure
trustworthy
and
effective
AI
application.
We
encourage
other
companies
to
follow
suit,
and
the
Global
Digital
Compact
could
draw
attention
to
such
industry-led
principles
to
inform
its
work
on
AI
moving
forward.
We
welcome
efforts
by
policymakers
around
the
world
to
develop
proportional,
risk-based
regulations
that
promote
reliable,
robust
and
trustworthy
AI
applications,
while
still
enabling
innovation
and
the
promise
of
AI
for
societal
benefit.
Indeed,
the
“Global
Digital
Compact:
Background
Note
(version
17
January
2023)”
stated
that
“the
Compact
could
also
promote
regulation
of
artificial
intelligence
to
ensure
that
this
is
aligned
with
shared
global
values.”
We
agree.
The
challenge
is
to
do
so
in
a
way
that
is
proportionately
tailored
to
mitigate
risks
and
promote
reliable,
robust
and
trustworthy
AI
applications,
while
still
enabling
innovation
and
the
promise
of
AI
for
societal
benefit.
We
encourage
the
United
Nations
and
its
member
states
to
keep
this
in
mind
as
the
Global
Digital
Compact
unfolds.
We
believe
that
AI
has
the
potential
to
benefit
people
and
society
through
its
capacity
to:
●
Make
information
more
useful
and
available
to
more
people,
everywhere,
often
helping
overcome
barriers
including
access
and
language
●
Assist
people
and
organizations
to
make
decisions,
solve
problems,
be
more
productive
and
creative
in
their
daily
and
work
lives
●
Enable
innovation
that
leads
to
new,
helpful
products
and
services
for
people,
organizations,
and
society
more
broadly
●
Help
tackle
current
and
pressing
real
world
challenges,
such
as
public
health
crises,
natural
disasters
(early
warning
systems),
climate
change,
and
sustainability
●
Enable
scientific
and
other
breakthroughs
to
address
humanity’s
greatest
future
opportunities
and
challenges
(e.g.
medical
diagnosis,
drug
discovery,
climate
forecasting)
The
foundational
nature
of
AI
means
that
AI
will
also
power
and
transform
existing
infrastructure,
tools,
software,
hardware,
and
devices—including
products
and
services
not
normally
thought
of
as
AI.
A
non-exhaustive
list
of
our
products
that
are
already
being
transformed
by
AI
includes,
among
others,
Google
Search,
Google
Maps,
Google
Photos,
Google
Workspace,
Android,
and
Pixel
phones.
AI
will
significantly
enhance
their
usefulness
and
multiply
their
value
to
people.
It
will
also
lead
to
new
categories
of
assistive
tools,
products,
and
services,
often
with
breakthrough
capabilities
and
performance
made
possible
only
through
AI.
This
includes
quantum
computing,
robotics,
more
powerful
and
inclusive
language
translators,
conversational
AI
and
assistants,
generative
and
multi-modal
AI,
robotics
and
driverless
cars,
and
other
areas
that
our
research
teams
continue
to
work
on.
Our
goal
is
to
bring
to
users
useful
innovations
made
possible
by
AI
that
benefit
people
and
society.
Advancing
the
state
of
the
art
helps
us
expand
and
progress
AI
capability
to
deliver
innovations
that
can
assist
and
improve
the
lives
of
many,
while
generating
sustaining
value
that
enables
us
to
continue
investing
in
transformative
innovations.
We
are
pursuing
and
delivering
on
this
aspiration
in
several
ways:
A d v a n c e
t h e
s t a t e
o f
t h e
a r t
f o r
m o r e
c a p a b l e
A I
t h a t
c a n
b e n e f i t
p e o p l e
a n d
s o c i e t y :
●
Use
AI
to
make
breakthrough
progress
in
science
and
other
areas
where
we
aim
to
advance
scientific
and
engineering
progress.
Examples
of
our
widely-acknowledged
breakthroughs
in
AI
and
science
that
can
benefit
all
of
humanity
include:
mapping
nearly
all
known
proteins,
predicting
the
function
of
proteins,
mapping
a
piece
of
the
brain
in
neuroscience
research,
discovering
faster
algorithms,
and
advances
in
quantum
computing
and
physics
including
innovating
in
nuclear
fusion.
B r i n g
u s e f u l
a n d
t r a n s f o r m a t i o n a l
A I - p o w e r e d
i n f r a s t r u c t u r e ,
p r o d u c t s ,
a n d
s e r v i c e s
t o
m o r e
p e o p l e ,
b u s i n e s s e s ,
o r g a n i z a t i o n s
( l a r g e
a n d
s m a l l ) ,
a n d
e c o n o m i e s
e v e r y w h e r e :
●
Build
state
of
the
art
AI
infrastructure
that
is
secure
and
easy
to
use,
including
compute
(e.g.
Tensor
Processing
Units,
Google
Tensor
and
Colab)
and
widely-used
software
frameworks
(e.g.
TensorFlow,
Jax,
Android
ML
and
Private
Compute).
Make
this
AI
infrastructure
available
(with
many
open
source
tools)
to
millions
of
developers,
students,
and
researchers
in
various
organizations
throughout
the
world,
thus
enabling
digital
transformation.
●
Develop
new
AI-powered
products,
services
and
experiences
for:
○
Consumers
with
assistive
tools
like
Google
Translate,
Google
Lens,
Google
Assistant,
Project
Starline,
Project
Relate
and
Activate,
speech-to-text,
Pixel
Call
Assist
and
Recorder,
real-time
text
suggestions
and
summarization,
and
generative
human-assistive
capabilities
across
many
creative
and
productivity
endeavors.
To
enhance
all
products
that
use
speech,
we’ve
developed
a
Universal
Speech
Model
capable
of
400
languages
and
we
are
committed
to
building
a
model
to
support
the
1000
most-spoken
languages,
improving
access
for
billions
of
people.
○
Businesses
and
organization
s
of
all
sizes,
across
industries
and
regions,
with
examples
like
contact
center
assistive
agents,
tools
such
as
AutoML,
Vertex
AI,
Cloud
TPUs,
Glass
Enterprise,
and
assistive
products
for
coding,
design,
and
more
still
to
come.
○
Sectors
that
can
most
benefit
from
AI,
from
manufacturing
to
life
sciences
(e.g.
diabetic
retinopathy,
imaging
diagnostics,
DeepVariant).
W o r k
w i t h
a n d
e n a b l e
m a n y
o t h e r s
b e y o n d
G o o g l e
t o
a p p l y
A I
t o
h e l p
t a c k l e
s o c i e t y ’ s
g r e a t e s t
c h a l l e n g e s
a n d
o p p o r t u n i t i e s
t o d a y
a n d
i n
t h e
f u t u r e .
●
Collaborate
with
others
around
the
world
to
apply
AI
to
society’s
most
pressing
challenges
such
as
natural
disasters,
public
health
crises,
climate
change,
and
sustainability.
Notable
examples
include
AI
for
Social
Good,
AI
for
the
UN
Sustainable
Development
Goals,
Data
Commons,
wildfire
alerts,
coral
reef
conservation,
and
flood
forecasting
so
far
in
more
than
20
countries
around
the
world.
●
Jigsaw,
a
team
within
Google
that
builds
technology
to
address
threats
to
open
societies,
has
leveraged
advances
in
AI
to
build
a
free,
public
API
called
“Perspective,”
which
enables
moderators
from
over
800
publishers
and
platforms
to
identify
and
remove
toxic
comments,
thus
enabling
more
meaningful
and
less
hateful
conversations.
Jigsaw
also
open-sourced
“Harassment
Manager,”
a
free
tool
used
by
multiple
NGOs
that
allows
public
figures
including
journalists,
politicians
and
human
rights
defenders
to
block
and
document
the
harassment
they
receive
on
social
media
platforms
like
Twitter.
A p p l y
o u r
A I
i n n o v a t i o n s
t o
c o n t i n u a l l y
i m p r o v e
G o o g l e
i t s e l f
a s
a
l e a d i n g
o r g a n i z a t i o n ,
a n d
t o
s h a r e
w h a t
w e
l e a r n
w i t h
o t h e r
o r g a n i z a t i o n s ,
i n c l u d i n g
c u s t o m e r s ,
g o v e r n m e n t s ,
n o n - g o v e r n m e n t a l
o r g a n i z a t i o n s
a n d
i n t e r n a t i o n a l
o r g a n i z a t i o n s .
K e y
a r e a s
o f
f o c u s
i n c l u d e
:
●
Leveraging
AI
to
achieve
industry-leading
safety
and
cybersecurity
across
all
our
products
and
services.
●
Applying
AI
to
improve
our
own
productivity
and
operations
across
all
functions.
●
Using
AI
to
help
realize
bold
ambitions
in
climate
and
sustainability.
As
with
any
transformational
technology,
AI
comes
with
complexities
and
risks,
and
these
will
change
over
time.
As
an
evolving
technology,
its
ever-changing
capabilities
and
uses
create
potential
for
misapplication,
misuse,
and
unintended
or
unforeseen
consequences.
We
are
taking
a
proactive
approach
to
understand
the
evolving
complexities
and
risks
as
AI
advances,
deployment
grows,
and
use
expands,
while
continuing
to
learn
from
users
and
the
wider
community.
We
urge
other
companies
operating
in
this
space
to
do
the
same.
We
recognize
the
harms
that
these
failures
can
cause,
especially
for
different
communities
and
contexts
across
the
globe,
and
a
key
aim
of
the
Global
Digital
Compact
could
be
to
identify
best
practices
for
mitigating
the
above
risks
to
increase
trust,
ensure
safe
and
inclusive
user
experiences,
and
enable
AI
to
fully
benefit
people,
planet
and
society.
O u r
a p p r o a c h
t o
R e s p o n s i b l e
A I
Given
its
risks
and
complexities,
we
believe
that
we
as
a
global
company
must
pursue
AI
responsibly.
As
leaders
in
AI,
we
must
lead
not
only
in
state-of-the-art
AI
technologies,
but
also
in
state-of-the-art
responsible
AI.
In
2018,
we
were
one
of
the
first
companies
to
articulate
AI
Principles
that
put
beneficial
use,
users,
safety,
and
avoidance
of
harms
above
business
considerations,
and
we
have
pioneered
many
best
practices,
like
the
use
of
model
and
data
cards
now
widely
used
by
others.
A
year
later
in
2019,
Organization
for
Economic
Cooperation
and
Development
(OECD)
Member
States
agreed
on
their
own
AI
principles,
many
of
which
mirrored
our
own.
While
we
continue
to
push
the
frontiers
of
innovation
in
AI,
we
continue
to
learn
from
users,
other
researchers,
affected
communities,
and
our
experiences.
As
a
result,
we
are
continually
refining
our
approaches
to
ensure
that
the
above
considerations
are
incorporated
in
all
we
do
and
address
issues
as
they
arise.
We
aim
to
work
in
meaningful
ways
that
help
shape
but
do
not
slow
down
innovation
that
can
benefit
people,
planet
and
society.
W h y
a
c o l l e c t i v e
a p p r o a c h
t o
r e s p o n s i b l e
A I
i s
n e e d e d
-
a n d
h o w
t h e
U N
G l o b a l
D i g i t a l
C o m p a c t
c a n
h e l p
:
We
believe
that
getting
AI
right
requires
a
collective
effort
at
a
global
scale.
We
do
not
have
all
the
answers,
but
our
experience
so
far
suggests
that
everyone
involved
in
AI
(researchers,
developers,
deployers,
academics,
civil
society,
governments,
and
users,
including
individuals,
businesses,
and
other
organizations)
must
work
together
to
get
AI
right
including
in
the
following
areas:
●
Responsible
approaches
to
AI
development
and
deployment
of
AI
systems
●
Data
and
privacy
practices
that
protect
privacy
and
enable
benefits
for
people
and
society
(e.g.
sharing
traffic
and
public
safety
data)
●
Robust
AI
infrastructure
and
cybersecurity
to
mitigate
security
risks
●
Regulations
that
encourage
innovation
and
safe
and
beneficial
uses
of
AI
and
avoid
misapplications,
misuse,
or
harmful
uses
of
AI
●
Cross-community
collaboration
to
develop
standards
and
best
practices
●
Sharing
and
learning
together
with
leaders
in
government
and
civil
society
●
Practical
accountability
mechanisms
to
build
trust
in
areas
of
societal
concern
●
Investment
in
AI
safety,
ethics,
and
sociotechnical
research
●
Growing
a
larger
and
more
diverse
community
of
AI
practitioners
to
fully
reflect
the
diversity
of
the
world
and
to
better
address
its
challenges
and
opportunities
We
would
encourage
the
Global
Digital
Compact
to
reflect
such
practices
to
ensure
that
the
Compact
is
indeed
aligned
with
shared
global
values.
6 )
C o n t e n t
R e s p o n s i b i l i t y
( S D G
1 6 )
Core
to
our
mission
is
providing
trustworthy
content
and
opportunities
for
free
expression
across
our
platforms,
while
limiting
the
reach
of
misinformation/disinformation,
violent
extremism,
and
other
harmful
content.
These
are
not
easy
issues,
which
is
why
we
support
collaborative
efforts
that
enable
companies
like
Google
to
continue
the
work
we
are
already
doing
to
develop
clear
and
transparent
policies
and
enforce
them
without
regard
to
political
party
or
point
of
view.
We
work
to
raise
up
authoritative
sources,
and
reduce
the
spread
of
harmful
content,
in
recommendations
and
elsewhere.
Teams
across
the
company
work
in
a
variety
of
roles
to
help
develop
and
enforce
our
policies,
monitor
our
platforms
for
abuse,
and
protect
users
from
everything
from
account
hijackings
and
disinformation
or
harassment
campaigns
to
terrorist
content
and
inauthentic
activity.
Beyond
our
own
platforms,
Google’s
Jigsaw
team
is
also
developing
new
approaches
to
proactively
protect
the
integrity
of
information
across
the
internet
through
initiatives
like
disinformation
“prebunking”,
and
building
tools
that
allow
other
platforms
and
organizations
to
identify
and
remove
toxic
comments
or
violent
extremist
content
before
it
spreads.
Jigsaw’s
tools
are
free
and
open-sourced,
and
its
research
is
regularly
published
to
benefit
the
broader
ecosystem.
R e c o m m e n d a t i o n s
Already,
multiple
international
and
regional
fora
have
elevated
this
workstream.
We
would
strongly
encourage
any
GDC
initiative
or
UN
Code
of
Conduct
on
Public
Integrity
and
Information
to
reference
and
draw
upon
the
following
pre-existing
initiatives
to
minimize
duplication
and
ensure
any
global
regulatory
framework
is
fit
for
purpose.
Specifically,
we
would
like
to
draw
attention
to
the
Global
Principles
on
Digital
Safety
,
developed
by
WEF
which
provide
a
number
of
helpful
reference
points.
The
Principles
aim
to
advance
digital
safety
in
a
rights-respecting
way,
drive
multi-stakeholder
alignment,
and
enable
positive
behaviors
and
actions
across
the
digital
ecosystem.
In
addition,
the
EU
2022
Code
of
Practice
on
Disinformation
,
which
Google
and
30+
other
companies
and
organizations
have
committed
to,
serves
as
another
helpful,
multilateral
reference
point
that
incorporates
constructive
input
from
stakeholders.
In
addition
to
this,
the
Christchurch
Call
serves
as
yet
another
example
of
governments
and
tech
converging
to
strengthen
joint
responses
to
online
terror
events.
The
Christchurch
Call
is
a
community
of
over
120
governments,
online
service
providers,
and
civil
society
organizations
acting
together
to
eliminate
terrorist
and
violent
extremist
content
online
and
one
in
which
we
played
a
leading
role.
Lastly,
the
Global
Network
Initiative
(GNI)
could
also
help
to
inform
the
UN’s
work
moving
forward.
The
GNI
Principles
and
Implementation
Guidelines
provide
an
evolving
framework
for
responsible
company
decision
making
in
support
of
freedom
of
expression
and
privacy
rights.
Google
is
an
active
member
and
the
GNI
Principles
are
taking
root
as
a
global
standard
for
human
rights
in
the
ICT
sector.
O u r
a p p r o a c h
t o
i n f o r m a t i o n
q u a l i t y
There
are
inherent
tensions
that
come
with
fulfilling
our
mission
to
organize
the
world’s
information
and
make
it
universally
accessible
and
useful.
We
must
strike
a
careful
balance
between
the
free
flow
of
information,
safety,
efficiency,
accuracy,
and
other
competing
values
and
we
hope
that
our
approach
will
be
accurately
reflected
in
any
future
UN
Code
of
Conduct
to
Promote
Integrity
in
Public
Information
and
the
UN
Global
Digital
Compact.
To
help
inform
both
processes,
we
would
like
to
highlight
that
the
product,
policy,
and
enforcement
decisions
we
make
in
this
complex
environment
are
guided
by
a
set
of
considerations
that
are
consistent
across
the
spectrum
of
our
products
and
services:
●
V a l u e
o p e n n e s s
a n d
a c c e s s i b i l i t y
:
We
aim
to
provide
access
to
an
open
and
diverse
information
ecosystem.
But
that
does
not
mean
that
anything
and
everything
goes
on
our
services.
Removal
of
content
is
an
important
lever
we
use
to
address
information
quality.
However,
it
is
not
the
only
lever
at
our
disposal,
and
we
use
it
with
caution,
particularly
in
the
context
of
Search.
We
believe
that
a
healthy
and
responsible
approach
to
supporting
information
quality
should
aim
toward
keeping
content
accessible.
●
R e s p e c t
u s e r
c h o i c e
:
Users
who
express
an
intent
to
explore
content
that
is
not
illegal
or
prohibited
by
our
policies
should
be
able
to
find
it,
even
if
all
available
indicators
suggest
it
is
of
relatively
low
quality.
We
set
a
higher
bar
for
information
quality
where
users
have
not
clearly
expressed
what
they
are
looking
for.
●
B u i l d
f o r
e v e r y o n e
:
Our
services
are
used
around
the
world
by
users
from
different
cultures,
languages,
and
backgrounds,
and
at
different
stages
in
their
lives.
Some
have
always
known
a
world
with
smartphones,
while
others
have
lived
most
of
their
lives
without
access
to
the
web.
Our
product
and
policy
development,
as
well
as
our
policy
enforcement
decisions,
take
into
account
the
diversity
of
our
users
and
seek
to
address
their
needs
appropriately.
Each
of
the
products
and
services
we
offer
has
a
different
purpose,
and
people
have
different
expectations
of
what
kind
of
content
they
will
interact
with.
So,
we
tailor
our
approach
to
the
content
that
should
be
available
on
each
product
and
service
carefully.
For
example,
Google
Chrome
is
a
tool
for
viewing
the
breadth
of
content
on
the
internet,
warning
only
of
pages
potentially
infected
by
malware.
Google
Search
serves
as
an
index
of
all
pages
available
on
the
open
web,
where
users
expect
to
find
every
legal
webpage
pertaining
to
their
query.
Therefore,
it
leans
toward
the
least
restrictive
end
of
that
spectrum.
On
the
other
end,
our
advertising
products
are
among
the
most
restrictive,
as
we
do
not
want
to
profit
from
those
who
create
harmful
content
or
experiences.
Other
products
fall
elsewhere
on
the
spectrum.
For
instance,
Gmail
involves
minimal
limitations
on
content,
while
YouTube
is
a
platform
for
uploading
and
sharing
content
as
part
of
a
community,
which
requires
broader
prohibitions
than
Google
Search.
It
is
important
to
note
that
some
features
of
Google
Search,
like
Autocomplete,
provide
information
to
help
people
get
to
the
results
they
are
looking
for
as
quickly
as
possible.
But
we
also
want
to
be
careful
not
to
show
potentially
upsetting
content
to
people
when
they
haven’t
asked
for
it.
For
these
features,
we
have
developed
policies
to
exclude
things
like
child
sexual
abuse
materials
or
violence
from
appearing.
Actions
taken
on
these
features
do
not
limit
what
users
can
search
for.
We
rely
on
four
complementary
levers
to
support
information
quality
and
moderate
content
across
many
of
our
products
and
services:
●
R e m o v e
:
We
set
responsible
rules
for
each
of
our
products
and
services
and
take
action
against
content
and
behaviors
that
infringe
on
them.
We
also
comply
with
legal
obligations
requiring
the
removal
of
content.
●
R a i s e
:
We
elevate
high-quality
content
and
authoritative
sources
where
it
matters
most.
●
R e d u c e
:
We
reduce
the
spread
of
potentially
harmful
information
where
we
feature
or
recommend
content.
●
R e w a r d
:
We
set
a
high
standard
of
quality
and
reliability
for
publishers
and
content
creators
who
would
like
to
monetize
or
advertise
their
content.
These
levers
allow
us
to
be
consistent
in
our
methodology
across
products
while
tailoring
their
implementation
to
fit
the
uses
and
needs
of
each.
7 )
P r o m o t e
t h e
u s e
o f
t e c h n o l o g y
i n
w a y s
t h a t
a d v a n c e
s u s t a i n a b i l i t y
( S D G s
6 ,
7 ,
1 1 ,
1 2 ,
1 3 ,
1 4 ,
1 5 )
As
Secretary-General
Guterres
said,
“Looking
to
the
future,
two
seismic
shifts
will
shape
the
21st
century:
the
climate
crisis,
and
digital
transformation.”
In
our
founding
decade,
Google
became
the
first
major
company
to
be
carbon
neutral.
In
our
second
decade,
we
were
the
first
major
company
to
match
100%
of
our
annual
electricity
use
with
renewable
energy.
By
2030,
we
aim
to
be
the
first
major
company
to
operate
on
24/7
carbon-free
energy.
But
this
alone
is
not
enough.
Beyond
Google,
a
grid
powered
by
clean
energy
will
reduce
a
major
source
of
greenhouse
gas
emissions
and
unleash
sustainable
innovation
in
other
parts
of
our
economy,
like
electrification
of
the
transportation
sector.
This
is
good
for
the
planet,
good
for
people,
and
good
for
business.
But
for
us
and
other
companies
to
realize
this
future,
we
need
to
galvanize
investment
and
modernization
of
the
world’s
energy
infrastructure,
continue
to
tackle
misinformation
on
climate
change,
and
accelerate
the
sharing
of
technology,
methods,
and
funding
to
help
all
people
transition
to
resilient,
carbon-free
systems.
Digital
efforts
will
play
a
key
role
in
this
energy
transition.
We
stand
committed
to
helping
organizations
around
the
world
accelerate
advances
in
climate
information
and
action,
driven
by
open
data,
AI,
machine
learning
and
other
digital
tools,
and
support
efforts
to
facilitate
collaboration
worldwide.
8 )
W e
m u s t
p r o t e c t
d a t a
a n d
e n s u r e
p o r t a b i l i t y
( S D G
9 )
Data
portability
is
fundamental
to
promoting
consumer
choice
and
data
protection.
We
believe
data
portability
is
a
secure
way
to
foster
innovation
and
competition
among
digital
service
providers.
When
people
can
easily
switch
to
a
new
product
or
service,
without
the
fear
of
losing
access
to
their
data,
companies
are
encouraged
to
provide
the
best
possible
services
to
win
over
new
users.
For
over
a
decade,
Google
has
offered
its
users
data
portability
–
the
ability
to
take
your
Google
data
with
you,
even
if
you
are
no
longer
using
a
Google
service.
We
believe
data
portability
rules
should
follow
three
key
principles:
●
P u t
p e o p l e
f i r s t
.
Data
portability
supports
competition
by
empowering
consumers.
Supporting
standards
for
the
most
common
data
types
will
accelerate
innovation
in
products
that
have
a
high
value
for
consumers
—
including
services
for
photos,
playlists
and
contacts.
●
R e q u i r e
e x p o r t a b i l i t y
.
Platforms
that
allow
people
to
import
their
data
should
also
allow
them
to
export
it.
This
encourages
people
to
try
new
services
without
the
risk
that
they
will
lose
their
data.
Consumers
will
be
more
likely
to
try
something
new
if
they
know
they
can
change
their
mind.
●
P r i o r i t i z e
p r i v a c y
a n d
s e c u r i t y
.
Portability
regulation
must
include
safeguards
against
unauthorized
access,
diversion
of
data,
and
other
types
of
fraud.
This
should
include
account
authorization,
encryption
and
delayed
delivery.
9 )
W e
m u s t
p r o m o t e
r e s p o n s i b l e
o p e n
s o u r c e
a n d
o p e n
d a t a .
( S D G
9 )
At
Google
we
have
long
believed
that
open
data
and
open
source
are
good
not
only
for
us
and
our
industry,
but
also
benefit
the
world
at
large.
  More
accessible
data
can
meaningfully
help
people
and
organizations,
and
we
are
doing
our
part
by
opening
datasets,
providing
access
to
APIs
and
aggregated
product
data,
and
developing
tools
to
make
data
more
accessible
and
useful.
What
makes
data
useful
is
how
easily
it
can
be
analyzed.
Though
there
is
more
open
data
today,
data
scientists
spend
significant
time
analyzing
it
across
multiple
sources.
That
can
take
days
or
weeks.
We’ve
developed
tools
at
Google
like
our
Data
Commons
to
make
that
easier,
but
we
are
supportive
of
further
efforts
to
promote
common
datasets.
There
are
also
trade-offs
to
opening
up
data,
and
we
believe
it
is
essential
that
the
global
community
balance
various
sensitivities
with
the
potential
benefits
of
sharing.
One
consideration
is
that
broad
data
openness
can
facilitate
uses
that
do
not
align
with
our
AI
Principles.
Extreme
data
openness
can
also
risk
exposing
user
or
proprietary
information,
causing
privacy
breaches
or
threatening
the
security
of
our
platforms.
We
allow
third
party
developers
to
build
on
services
like
Maps,
Gmail
and
more
via
APIs,
so
they
can
build
their
own
products
while
user
data
is
kept
safe.
We
also
publish
aggregated
product
data
like
Search
Trends
to
share
information
of
public
interest
in
a
privacy-preserving
way.
While
there
can
be
benefits
to
using
sensitive
data
in
controlled
and
principled
ways,
like
predicting
medical
conditions
or
events,
it
is
critical
that
safeguards
are
in
place
so
that
training
machine
learning
models
does
not
compromise
individual
privacy
and
we
encourage
UN
Member
States
to
be
mindful
of
these
tradeoffs
as
the
Global
Digital
Compact
moves
forward.
—
While
we
continue
to
push
the
frontier
of
bold
yet
responsible
innovation,
Google
is
committed
to
supporting
the
UN
Global
Digital
Compact
to
use
technology
to
tackle
humanity’s
collective
challenges,
both
now
and
in
the
future.