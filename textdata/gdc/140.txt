S u b m i s s i o n
t o
t h e
G l o b a l
D i g i t a l
C o m p a c t
T h e m a t i c
a r e a :
R e g u l a t i o n
o f
A r t i f i c i a l
I n t e l l i g e n c e
April
2023
O V E R V I E W
About
the
AI
Future
Lab
The
AI
Future
Lab
was
founded
in
2021
following
the
W orld
Economic
Forum’ s
Global
Shapers
Community
initiative.
W e
are
the
go
to
place
for
youth
to
learn
and
get
involved
in
all
aspects
of
artificial
intelligence
from
technology
development
to
design
to
policy
and
ethics.
The
AI
Future
Lab
creates
a
unified
space
for
leadership,
research,
data-driven
projects,
networking,
and
community
building
around
artificial
intelligence
for
young
people
around
the
globe.
Introduction
Recently ,
there
has
been
unprecedented
ef forts
to
reign
in
the
wide-spread
harm
from
the
deployment
of
artificial
intelligence.
Regulation
has
been
a
pivotal
tool
in
addressing
AI
failures
and
mitigating
the
risks
associated
with
AI.
However ,
simply
imposing
regulations
without
considering
the
unique
characteristics
of
AI
can
lead
to
unintended
consequences,
stifling
innovation
and
progress.
It
is
important
to
develop
regulations
that
are
socially
grounded,
that
promote
anti-erosion,
ensure
agency ,
and
are
reinforced
through
integration,
while
also
highlighting
responsibility .
Ef fective
regulation
should
be
designed
with
participatory
mechanisms
that
allow
for
input
from
a
diverse
set
of
stakeholders,
including
non-experts.
Additionally ,
there
should
be
a
focus

on
empowering
individuals
through
awareness
and
oversight,
and
ensuring
equitable
resource
sharing
to
avoid
exacerbating
existing
power
imbalances.
This
submission
calls
for
an
inclusive
approach
to
AI
regulation
that
is
reflective
of
the
responsible
principles
that
people
desire
by
challenging
long
standing
systemic
issues
that
have
plagued
the
ef fectiveness
and
development
of
AI
regulation.
By
implementing
these
principles
and
taking
action
to
promote
responsible
AI
development,
we
can
create
a
world
where
the
benefits
of
AI
are
realized
while
minimizing
potential
harm.
C O R E
P R I N C I P L E S
W e
recommend
the
following
principles
for
regulating
the
potential
risks
of
artificial
intelligence
systems:
●
Regulation
that
is
socially
grounded
:
The
regulation
of
AI-related
risks
should
be
centered
around
benefits
for
society
at
large
versus
solely
minimizing
or
penalizing
risk.
Therefore,
regulatory
and
policy
forces
should
foster
deeper
ef forts
to
extend
assessment
criteria
in
the
design
and
development
of
AI
that
account
for
existing
social
dif ficulties,
identify
how
the
proposed
innovation
would
improve
conditions,
and
decrease
existing
inequalities.
●
Regulation
that
promotes
anti-erosion
:
Generations
of
new
technological
paradigms
would
be
expected
to
transform
processes
but
it
should
not
erode,
erase,
and
silence
entire
populations
for
the
sake
of
innovation.
AI
regulation
should
explicitly
provide
statutes
and
legislative
protections
to
address
gross
negligence
of
representational
harms
especially
in
cases
where
those
af fected
are
not
able
to
actively
participate
in
the
development
of
corrective
measures.
●
Regulation
that
ensures
agency
:
Regulators
have
advocated
for
greater
accountability
and
control
within
AI
systems.
Future
AI
regulation
should
build
further
on
these
ef forts
by
mandating
greater
agency
for
users
over
their
data,
the
processing
and
ownership
of
their
data,
and
the
right
to
be
notified
of
and
meaningfully
withdraw
from
harmful
AI
systems
or
spaces
where
people
experience
AI
failures.
●
Regulation
that
is
reinforced
through
integration
:
AI
preparedness
and
the
maturity
of
AI
regulation
dif fers
substantially
across
regions.
It
will
take
considerable
ef forts
to
ensure
more
comparable
levels
of
readiness.
However ,
mechanisms
could
be
implemented
to
promote
equitable
resource
sharing
to
avoid
obvious
gaps
and
entire
regions
being
decades
behind
in
regulation
while
known
AI
failures
continue
to
persist
in
the
absence
of
regulation.
●
Regulation
highlights
responsibility
:
Further
refinement
is
needed
to
ascertain
what
should
be
assessed
whether
applications
or
entire
systems,
who
should
bear
the
responsibility ,
and
how
liability
should
be
determined.
This
line
of
inquiry
pushes
stakeholders
to
reconsider
and
substantiate
claims
about
widespread
transformations
and
applicability
of
AI
to
address
social
ills
without
pondering
on
risks
to
the
responsible
development
of
AI.
SUGGESTED
COMMITMENTS/PLEDGES/ACTIONS
W e
recommend
the
following
commitments/pledges/actions
for
regulating
the
potential
risks
of
artificial
intelligence
systems:
●
Increase
participatory
design
among
legislators
and
stakeholders
It
is
equally
important
to
include
and
open
collaboration
across
stakeholders
from
civil
society ,
industry ,
academia,
as
well
as
non-experts.
By
extending
opportunities
to
actively
work
on
solutions,
it
breaks
down
barriers
that
would
keep
resources
in
silos,
shatters
walls
that
would
be
raised
from
personal
biases
within
any
particular
domain,
and
increases
chances
of
learning
from
the
lived
experiences
of
others.
This
can
be
accomplished
through
participatory
workshops
or
mini-conferences
led
by
international
bodies
with
an
agenda
that
answers
the
following:
1.
How
can
we
work
t o
enhance
understandings
between
and
bring
oppositely
positioned
gr oups
closer
t ogether
in
contexts
par ticularly
wher e
right
and
wr ong
is
hea vily
contested?
2.
How
can
we
encour age
multiple
v oices
t o
activ ely
par ticipate
in
r espectfully
pushing
back
on
diff er ent
AI
technologies
without
stiﬂing
inno v ation?
3.
How
could
we
r eimagine
pr ocesses
within
the
AI
r egulat or y
ecosystem
t o
str eamline
policy
that
sta ys
on
pace
with
technology?
4.
What
should
be
included
and
ex cluded
fr om
the
Global
r egulat or y
agendas
and
who
should
decide?
●
Promote
user
empowerment
through
enhanced
awareness
Empowerment
through
awareness
should
receive
greater
attention
to
further
compliment
AI
regulation
and
policy .
People,
regardless
of
their
education,
income,
or
age,
should
be
knowledgeable
about
their
rights
and
the
pathways
to
justice.
Regulatory
reporting
tools
for
example
should
be
easily
accessible
to
the
most
vulnerable
and
protections
from
regulations
should
be
communicated
in
ways
that
are
easy
to
consume.
Recommended
pathways
for
this
directions
are
mostly
centered
around
educational
campaigns
that
could
mobilize
civil
society
organizations
that
actively
work
at
relevant
AI
regulation
and
education
cross-sections.
●
Establish
equitable
resource
sharing
T o
address
disparities
in
resources
to
ef fectively
respond
to
AI
failure
through
regulation,
greater
steps
need
to
be
enforced
to
actively
correct
this
trajectory .
More
tools
and
resource
hubs
could
be
established
to
assist
with
smaller
scale
organizations
who
are
interested
in
implementing
responsible
AI
with
hopes
of
aligning
with
regulation.
Moreover ,
ef fective
information
streams
could
be
promoted
by
international
bodies
such
as
the
Of fice
of
the
Secretary-General's
Envoy
on
T echnology
to
highlight
opportunities
for
joint
or
open-sourced
agreements
that
would
better
improve
AI
preparedness
and
regulation
worldwide.