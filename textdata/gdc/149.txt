R 3 D ’ s
I n p u t
s u b m i t t e d
t o
t h e
G l o b a l
D i g i t a l
C o m p a c t
c o n s u l t a t i o n
R 3 D :
R e d
e n
D e f e n s a
d e
l o s
D e r e c h o s
D i g i t a l e s
i s
a
M e x i c a n
n o n - g o v e r n m e n t a l
o r g a n i z a t i o n
d e d i c a t e d
t o
p r o t e c t i n g
a n d
p r o m o t i n g
h u m a n
r i g h t s
i n
t h e
d i g i t a l
e n v i r o n m e n t .
W e
u s e
o u r
l e g a l ,
a n a l i t i c a l ,
a n d
c o m m u n i c a t i o n
c a p a c i t i e s
t o
r e v i e w
l e g a l
i n i t i a t i v e s ,
p u b l i c
p o l i c i e s ,
a n d
o t h e r
s o r t s
o f
( p u b l i c
a n d
p r i v a t e )
a c t i o n s
t h a t
c a n
l i m i t
o r
v i o l a t e
r i g h t s
s u c h
a s
f r e e d o m
o f
e x p r e s s i o n
a n d
p r i v a c y
i n
t h e
d i g i t a l
w o r l d .
I .
P r o t e c t
d a t a
A .
C o r e
P r i n c i p l e s
f o r
D a t a
P r o t e c t i o n
Objectives:
(a)
Prevent
or
avoid
;
(b)
detect
;
and,
(c)
sanction/remedy
the
abuse
of
surveillance
measures.
Since
our
personal
lives
have
turned
into
data,
analysis
of
this
data
can
be
highly
revealing
and
invasive,
particularly
when
the
data
is
combined
and
aggregated.
Data
surveillance
is
the
business
model
of
the
Internet.
States
are
mandating
the
retention
of
data
for
historical
surveillance
purposes,
and
its
disclosure
to
and
use
by
public
authorities
is
largely
unregulated.
-
Current
legislation
on
the
interception
of
private
communications
and
government
surveillance
does
not
provide
a
comprehensive
definition
of
what
is
meant
by
private
communications
that
includes
metadata.
-
Measures
restricting
the
right
to
privacy ,
especially
covert
surveillance
measures,
are
not
precise,
and
do
not
indicate
clear
and
detailed
rules
on
the
matter
nor
consider
essential
safeguards
to
protect
against
abuse.
-
Prohibition
of
the
deployment
of
mass
or
indiscriminate
surveillance
measures
–
There
are
regulations
in
the
Mexican
legal
system
that
contemplate
both
the
delivery
of
communications
data
and
the
real-time
monitoring
of
the
geographic
location
of
citizens
and
are
not
clear ,
precise
or
detailed
with
respect
to
the
cases,
circumstances
and
procedures
in
which
their
private
sphere
may
be
invaded,
and
therefore
do
not
comply
with
the
requirements
of
necessity
and
proportionality .
A.
Fair
Information
Practice
Principles
are
implemented.
E.g.
data
minimization,
purpose
specification,
use
limitation,
individual’ s
consent.
B.
Prior
and
permanent
judicial
control
for
surveillance
measures
and,
in
exceptional
cases,
immediate
judicial
control
for
geographic
location
measures,
in
real
time,
and
access
to
retained
data.
1.
Register
of
judicial
control.
Detailed
record
of
surveillance
measures
whose
authorization
is
requested/granted
by
the
Federal
Judicial
Branch
(e.g.
authorities,
subjects,
methods,
systems
or
tools
used
in
surveillance
measures).
2.
Modification
of
emergency
mechanisms.
Reformulate
emergency
mechanisms,
so
that:
(a)
the
request
for
ratification
of
surveillance
measures
is
sent
to
the
competent
Control
Judge
simultaneously
to
any
request
or
at
the
beginning
of
the
measure
itself;
and,
(b)
establish
the
procedure
to
be
followed
when
the
ratification
order
is
denied,
which
should
include
notification
to
the
af fected
person
and
appropriate
disciplinary
procedures.
3.
Supervision
of
measures.
Strengthen
technical
and
administrative
mechanisms
that
allow
the
supervision
of
the
judicial
authority
to
be
carried
out
autonomously ,
without
the
need
for
cooperation
or
knowledge
on
the
part
of
the
authority
that
carries
out
damaging
data
harvesting
practices
&
surveillance
measures.
C.
Recognition
of
the
right
of
notification.
1.
Obligation
to
notify
persons
whose
data
has
been
misused
or
has
been
subject
to
a
surveillance
measure.
2.
Judicial
control
of
the
process,
and
the
possibility
of
deferring
notification,
for
a
certain
period
of
time,
when
necessary
to
safeguard
a
legitimate
interest.
3.
Obligation
of
collaboration
on
the
part
of
concessionaires
authorized
to
provide
telecommunications
services,
as
well
as
providers
of
applications,
contents
and
services
on
the
Internet
that
collaborate
with
security
and
justice
authorities
to
carry
out
the
corresponding
notification.
D.
Strengthening
the
powers
of
oversight,
auditing
and
independent
supervision
of
surveillance
measures.
1.
Grant
powers
to
the
independent
supervisory
body
to
carry
out
surveillance,
audit
or
informal
verification
procedures
─including
on
a
random
basis─
to
verify
compliance
with
the
provisions
that
regulate
data
protection
&
surveillance
measures.
2.
Authorities’
power
to
access
and
request
any
information
necessary
to
carry
out
its
supervisory
function,
including
reserved
information
&
the
request
of
information
from
individuals
who
collaborate
with
authorities.
3.
Obligation
to
produce
a
periodic
and
public
report
on
the
findings
and
recommendations
of
the
supervisory
body .
b )
K e y
C o m m i t m e n t /
P l e d g e s /
A c t i o n s
1.
Moratorium
on
the
sale,
transfer
and
use
of
surveillance
technology
until
regulatory
frameworks
exist
and
are
in
line
with
HR
.
2.
Legal
&
administrative
reforms
for
democratic
controls
on
state
and
private
actors'
use
of
data/surveillance.
A)
Checks.
1.
Requirements/identification
of
agents
involved
in
the
decision-making
and
operation.
Establish
certification
requirements,
confidence
control
evaluations
and
a
detailed
registry
of
the
agents
who
have
been
trained/participate
in
data
harvesting
practices,
as
well
as
in
surveillance
measures.
2.
Usage
records/transparency .
Establish
mechanisms
that
ensure
a
detailed
record
of
data
usage
&
practices,
as
well
as
surveillance
measures
(e.g.
agents
involved,
subjects
&
methods
used).
3.
Mechanisms
to
protect
personally
identifiable
information
(PII).
Establish
the
obligation
to
implement
technical,
administrative
&
physical
measures
to
prevent
unregistered
uses,
modification,
loss,
destruction,
dissemination
&
disclosure
of
PII,
as
well
as
prevent
the
unregistered
surveillance
systems
or
alterations
in
the
use
registry .
B)
Clear ,
precise
and
detailed
definition
of
the
authorities,
procedures
&
circumstances
in
the
use
of
PII
&
surveillance
measures.
1.
Define
with
absolute
precision
and
clarity
which
authorities
have
the
power
to
create,
collect,
use,
process,
store,
maintain,
disseminate,
or
disclose
PII,
as
well
as
surveillance
measures
(SM),
including
those
that
do
not
require
the
collaboration
of
any
concessionaire
or
provider ,
as
well
as
the
cases
&
circumstances
in
which
the
federal
judicial
authority
may
authorize
SM.
2.
Explicit
recognition
that
surveillance
measures
may
only
be
authorized
by
a
federal
judicial
authority
when
it
is
a
suitable,
necessary
and
proportionate
measure.
3.
As
a
result,
massive
gathering
of
data
&
surveillance
measures
that
massively
compromise
the
integrity
and
security
of
communication
systems
should
be
expressly
prohibited.
1
C)
Accountability .
Establish
clear/harmonized
&
simple
national
procedural
laws
for
complaints
data
subjects
can
file
with
specialized
Data
Protection
Authorities
&
appropriate
judicial
remedies.
Safeguards:
C.
Guarantee
prior
and
permanent
judicial
control
for
surveillance
measures.
D.
Recognition
of
the
right
of
notification
.
E.
Creation
of
an
independent
oversight
body
or ,
failing
that,
the
development
of
such
powers
within
existing
impartial
bodies
I I .
R e g u l a t i o n
o f
a r t i f i c i a l
i n t e l l i g e n c e
A .
C o r e
p r i n c i p l e s
f o r
t h e
r e g u l a t i o n
o f
a r t i f i c i a l
i n t e l l i g e n c e
The
human-rights
approach
throughout
the
AI
lifecycle:
This
AI
regulation
should
focus
on
understanding
the
development
of
automated
systems
and
must
consider
human
rights
frameworks.
W e
must
broaden
the
scope
of
AI
regulation
to
be
more
than
ethics,
which
are
needed
but
could
be
understood
as
voluntary
or
non-binding
principles.
The
international
human
rights
law
(IHR)
framework
is
necessary
for
establishing
responsibilities
regarding
emerging
digital
technologies.
This
framework
must
establish
standard
ground
rules
for
protecting
human
rights
so
the
other
actors
involved
in
the
process
can
comply
with
their
obligations.
IHRL
is
vital
to
identify
human
rights
and
which
harms
could
af fect
them.
After
identifying
the
damage
to
human
rights
that
an
automated
system
can
commit
in
every
stage
of
the
AI
cycle,
the
regulation
can
establish
ef fective
preventive
measures
and
remedies.
T ransparency:
T ransparency
is
essential
for
developing
an
AI
system
with
a
human
rights
perspective.
T ransparency
must
be
understood
as
the
possibility
for
oversight
1
S u c h
a s
b e h a v i o r a l
a d v e r t i s i n g ,
t o
a v o i d
h a r m
( i n c l u d i n g
d i s c r i m i n a t i o n - r e l a t e d
h a r m s ,
d a t a 
b r e a c h e s ,
h a c k s
o r
u n a u t h o r i z e d
a c c e s s
o f
d a t a ) .
of
each
stage
of
the
AI
life
cycle,
specifically ,
the
design,
development,
and
deployment
process.
This
principle
includes
accessing
information
regarding
the
data
used
to
train
such
automated
systems,
the
benchmarks
used
to
evaluate
it,
the
business
model,
the
final
objectives
of
the
system,
etc.
This
information
is
critical
for
assessing
the
harms,
risks,
or
impact
these
technologies
will
have
on
human
rights.
Also,
it
can
provide
information
for
the
user
on
when
they
will
be
subject
to
automated
processing.
Non-discrimination:
even
though
this
principle
is
sometimes
named
“fairness,”
we
believe
that
this
principle
is
better
conceptualized
as
“non-discrimination.”
This
principle
often
refers
to
the
prevention
of
using
biased
data
to
develop
automated
systems
and
how
a
system
can
be
over
or
under-inclusive
in
its
decisions.
However ,
this
principle
also
includes
refraining
from
developing
AI
that
could
subject
people,
especially
vulnerable
groups,
to
direct
or
indirect
discrimination.
This
consideration
is
relevant
to
avoid
the
development
of
technology
whose
objectives
will
be
discriminatory ,
such
as
developing
AI
systems
that
do
racial
profiling
or
predictive
policing.
Privacy
and
data
protection.
The
right
to
privacy
and
data
protection
must
have
reinforced
protection
when
dealing
with
AI
regulation.
Due
to
the
invasiveness
of
these
technologies
and
the
scale
it
manages,
a
lack
of
protection
of
privacy
could
result
in
serious
human
rights
violations.
The
users
must
have
consented
to
the
treatment
of
their
data
and
have
control
over
their
information,
as
well
as
the
ability
to
restrict
data
processing
or
be
subjected
to
automated
processing.
B .
K e y
C o m m i t m e n t /
P l e d g e s /
A c t i o n s
●
Establish
human
rights
as
essential
for
AI
creation,
development,
and
deployment.
●
T ransparency
and
cooperation
with
stakeholders
must
be
ensured
as
a
ground
base.
●
The
developers
of
AI
must
ensure
that
their
systems
can
be
explainable
and
be
subjected
to
scrutiny
by
third
parties.
●
Develop
models
for
doing
human
rights
assessments
for
each
stage
of
the
AI
life
cycle
that
includes:
creation
or
design,
training,
evaluation,
development,
deployment,
funding,
and
implementation.
●
The
regulation
must
ensure
that
the
user ’ s
consent
is
always
considered.
Thus,
the
AI
systems
or
services
must
have
an
opt-out
option
if
the
user
does
not
want
to
be
subjected
to
AI
systems
to
access
a
service.
This
provision
will
be
critical
if
the
AI
systems
are
used
to
provide
a
public
service.
●
The
regulation
must
establish
a
mechanism
for
the
users
to
know
if
they
have
been
subjected
to
automated
processing
or
AI
systems.
Additionally ,
this
mechanism
must
ensure
that
people
can
access
an
effective
remedy
if
their
rights
are
affected
by
these
automated
systems.
●
Establish
a
moratorium
on
developing
and
implementing
AI
systems
directed
to
law
enforcement
that
haven’t
performed
any
human
rights
assessment
of
their
products.
●
Any
regulation
should
establish
that
authorities
must
evaluate
AI
systems
tailored
or
directed
towards
vulnerable
groups
with
special
attention
and
under
the
most
strict
scrutiny .